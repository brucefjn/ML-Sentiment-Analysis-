{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brucefjn/ML-Sentiment-Analysis-/blob/main/sentiment_prediction_system_(4).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiment Analysis with Transformer Fine-Tuning\n",
        "\n",
        "This project builds a sentiment classification system for movie reviews.\n",
        "\n",
        "Originally, the project began with a classical machine learning approach\n",
        "(TF-IDF + Logistic Regression).\n",
        "\n",
        "However, to build a more rigorous and modern system capable of understanding\n",
        "grammar and contextual meaning, the model was upgraded to a Transformer-based\n",
        "architecture (DistilBERT).\n",
        "\n",
        "Final model: Fine-tuned DistilBERT for binary sentiment classification.\n"
      ],
      "metadata": {
        "id": "V4osN0Olrkxl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Dataset\n",
        "\n",
        "The dataset consists of labeled movie reviews:\n",
        "\n",
        "- `Review`: raw text input\n",
        "- `Emotion`: sentiment label (positive / negative)\n",
        "\n",
        "We perform supervised learning using these labeled examples.\n"
      ],
      "metadata": {
        "id": "kW_9mU_1rr_d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O movie_reviews 'https://drive.google.com/uc?export=view&id=1kWs6yOYpdjVr-liLPs4PKIs1qSpIohzS'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxhTOdcggFIA",
        "outputId": "e0cba710-0a7f-4799-9ce2-d033fc6be96c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-02-14 01:43:49--  https://drive.google.com/uc?export=view&id=1kWs6yOYpdjVr-liLPs4PKIs1qSpIohzS\n",
            "Resolving drive.google.com (drive.google.com)... 74.125.130.101, 74.125.130.138, 74.125.130.113, ...\n",
            "Connecting to drive.google.com (drive.google.com)|74.125.130.101|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://drive.usercontent.google.com/download?id=1kWs6yOYpdjVr-liLPs4PKIs1qSpIohzS&export=view [following]\n",
            "--2026-02-14 01:43:49--  https://drive.usercontent.google.com/download?id=1kWs6yOYpdjVr-liLPs4PKIs1qSpIohzS&export=view\n",
            "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 172.217.194.132, 2404:6800:4003:c04::84\n",
            "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|172.217.194.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 31994890 (31M) [application/octet-stream]\n",
            "Saving to: ‘movie_reviews’\n",
            "\n",
            "movie_reviews       100%[===================>]  30.51M   119MB/s    in 0.3s    \n",
            "\n",
            "2026-02-14 01:43:54 (119 MB/s) - ‘movie_reviews’ saved [31994890/31994890]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Label Data\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "data = pd.read_csv('movie_reviews', delimiter=\",\")\n",
        "data.head(20)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "ixvBBotEg9hc",
        "outputId": "5ab1dbb7-dd79-40eb-8658-3b487c38296b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               Review   Emotion\n",
              "0   this could have been a good episode but i simp...  negative\n",
              "1   the film is severely awful and is demeaning to...  negative\n",
              "2   the first 30min of the flick was choppy and ha...  negative\n",
              "3   went to watch this movie expecting a nothing r...  negative\n",
              "4   im not sure what dragged me into the cinema to...  negative\n",
              "5   i had to write a review of this film after rea...  negative\n",
              "6   having not read the novel i cant tell how fait...  negative\n",
              "7   hiya folksbr br well this movie sucks really t...  negative\n",
              "8   the screenwriter poorly attempted to recreate ...  negative\n",
              "9   on the way back from imc6 san jose california ...  negative\n",
              "10  i came to new port south expecting a surrogate...  negative\n",
              "11  a damsel in distress is definitely not one of ...  negative\n",
              "12  me and a group of friends rent horrible videos...  negative\n",
              "13  for the lt to have chosen this one first the f...  negative\n",
              "14  as gently as i can i sincerely believe this mo...  negative\n",
              "15  this is a terrible film and not one scene has ...  negative\n",
              "16  i bought this dvd without any previous referen...  negative\n",
              "17  despite the excellent cast this is an unremark...  negative\n",
              "18  if you want to see womens breasts get a porno ...  negative\n",
              "19  anyone who visited driveins in the 1950s 60s a...  negative"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-df4bf8d0-b027-45ca-8093-e3fa1f03eb67\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>this could have been a good episode but i simp...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the film is severely awful and is demeaning to...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>the first 30min of the flick was choppy and ha...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>went to watch this movie expecting a nothing r...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>im not sure what dragged me into the cinema to...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>i had to write a review of this film after rea...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>having not read the novel i cant tell how fait...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>hiya folksbr br well this movie sucks really t...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>the screenwriter poorly attempted to recreate ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>on the way back from imc6 san jose california ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>i came to new port south expecting a surrogate...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>a damsel in distress is definitely not one of ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>me and a group of friends rent horrible videos...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>for the lt to have chosen this one first the f...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>as gently as i can i sincerely believe this mo...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>this is a terrible film and not one scene has ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>i bought this dvd without any previous referen...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>despite the excellent cast this is an unremark...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>if you want to see womens breasts get a porno ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>anyone who visited driveins in the 1950s 60s a...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-df4bf8d0-b027-45ca-8093-e3fa1f03eb67')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-df4bf8d0-b027-45ca-8093-e3fa1f03eb67 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-df4bf8d0-b027-45ca-8093-e3fa1f03eb67');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 24988,\n  \"fields\": [\n    {\n      \"column\": \"Review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 24892,\n        \"samples\": [\n          \"this is a gem of a movie not just for people who like fun and quirky premises but who love the history and traditions of scifi and classic hollywood movies each alien of the martian crew is the embodiment of a classic scifi character or member of hollywood royalty and its pure pleasure watching them bounce of each other and the residents of big bean\",\n          \"a very enjoyable film that features characters who do bad things and who let emotions like anger and a desire for vengeance bubble over the cast is very good theres plenty of action and stewart gets the girl and his revenge with a twist in the end ive seen this film several times and always watch when its on amc or cable highly recommended\",\n          \"i would just like all of the fans of this documentary to know that martin torgoff is my uncle and i am so darn proud of him this miniseries that in shown on vh1 is a great look at the culture of drugs in the past 30 years and my uncle worked very hard on it the amount of time and effort that i have watched him put into this documentary and the book that started it all cant find my way home makes it that much better to watch him on tv i know that he loves what he does and he does it well his eloquence is shown in the interviews which he did himself and the amazing additions that he himself adds to the commentary from the music to the videos and everything in between this is a great documentary that really shows the experience of the drug culture through the eyes of someone who lived through it i appreciate any comments on this from those who enjoyed it or didnt and would love to hear from fans three cheers for uncle martin\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Emotion\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"positive\",\n          \"negative\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Dataset Inspection\n",
        "\n",
        "We inspect:\n",
        "\n",
        "- Total dataset size\n",
        "- Class distribution\n",
        "- Label balance\n",
        "\n",
        "This ensures the dataset is suitable for supervised learning.\n"
      ],
      "metadata": {
        "id": "QmOMnBImsG-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = data['Review']\n",
        "y = data['Emotion']"
      ],
      "metadata": {
        "id": "GkrlLo1NiPCy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install transformers datasets accelerate torch scikit-learn\n"
      ],
      "metadata": {
        "id": "oQ8-VFesijIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer"
      ],
      "metadata": {
        "id": "NowAFjRSc4A1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Label Encoding\n",
        "\n",
        "Sentiment labels are mapped to numeric IDs to allow\n",
        "training using cross-entropy loss.\n"
      ],
      "metadata": {
        "id": "GFe7_5QVsffB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = data[[\"Review\", \"Emotion\"]].dropna()\n",
        "\n",
        "# Map labels to ids\n",
        "labels = sorted(data[\"Emotion\"].unique())\n",
        "label2id = {l: i for i, l in enumerate(labels)}\n",
        "id2label = {i: l for l, i in label2id.items()}\n",
        "\n",
        "data[\"label\"] = data[\"Emotion\"].map(label2id)\n",
        "\n",
        "print(\"Labels:\", labels)\n",
        "print(data[\"Emotion\"].value_counts())\n",
        "print(\"Total rows:\", len(data))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETnsOyqThzdA",
        "outputId": "a5e851b2-bcaa-4874-afc4-0629c482dbed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels: ['negative', 'positive']\n",
            "Emotion\n",
            "negative    12496\n",
            "positive    12492\n",
            "Name: count, dtype: int64\n",
            "Total rows: 24988\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Train-Test Split\n",
        "\n",
        "The dataset is split into:\n",
        "\n",
        "- 80% training data\n",
        "- 20% testing data\n",
        "\n",
        "Stratified sampling preserves class proportions.\n"
      ],
      "metadata": {
        "id": "cXmJUf4Bsits"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, test_df = train_test_split(\n",
        "    data,\n",
        "    test_size=0.2,\n",
        "    random_state=20,\n",
        "    stratify=data[\"label\"]\n",
        ")\n",
        "\n",
        "print(\"Train:\", len(train_df), \"Test:\", len(test_df))\n",
        "\n"
      ],
      "metadata": {
        "id": "i4xWUqA1jNPe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d720633b-8592-4580-e4d2-8b1e42857a3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 19990 Test: 4998\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = Dataset.from_pandas(train_df[[\"Review\", \"label\"]])\n",
        "test_ds  = Dataset.from_pandas(test_df[[\"Review\", \"label\"]])"
      ],
      "metadata": {
        "id": "nJ1Z8DgJk15K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Tokenization\n",
        "\n",
        "Raw text is converted into token IDs using a pretrained\n",
        "DistilBERT tokenizer.\n",
        "\n",
        "This enables contextual embedding and grammar-aware modeling.\n"
      ],
      "metadata": {
        "id": "KAV7ennWsruQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"distilbert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "def tokenize(batch):\n",
        "    return tokenizer(\n",
        "        batch[\"Review\"],\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=256\n",
        "    )\n",
        "\n",
        "train_ds = train_ds.map(tokenize, batched=True)\n",
        "test_ds  = test_ds.map(tokenize, batched=True)\n",
        "\n",
        "cols = [\"input_ids\", \"attention_mask\", \"label\"]\n",
        "train_ds.set_format(type=\"torch\", columns=cols)\n",
        "test_ds.set_format(type=\"torch\", columns=cols)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "d4639e2a548442b2b87172998dd3c22f",
            "b0612cb8908f4424b62194ab590683c1",
            "4edd25acafb6463f880a904aef9fe93a",
            "339a2450e9e542179ba7cf2f0c69bf09",
            "dd6d6fcc069d4e18a63e7655b111f449",
            "4cb40179a8b34fd2a8b8811104844b26",
            "c509df61d9654153bc88a6a951066a18",
            "53d4f2adbeef4b2381079d86eb86effc",
            "d31c8561d180437fad40daa0857d460d",
            "9ace10b576d54250ae9fa8f5737be0e8",
            "d2f371df90854d0eba4a00c41c7e0d9a",
            "f4f6c7a1b90a42538e47ed3ece42b12e",
            "4c95692f11fc48198fa4a42fb1c98370",
            "5e48caadbe29464c99ae886c8c6e9e65",
            "e04de975479b4cb8891b28f8db049616",
            "d1f37378e2bf431fb30e1ab818d5ee59",
            "7b2f997d109241398f374b1835db615d",
            "e932761e8a394273b9241f02645a95c4",
            "22ed2344e0c941a09771df7e7fbf6ada",
            "44d0c41004804b5bb947d5845ac7db40",
            "2e255e96a99e47e9abfc1e328e3d3ea2",
            "244258770d444f9f932ef095f82bada3"
          ]
        },
        "id": "rdGiXMApYNT6",
        "outputId": "cdd5b53d-400c-4d0a-f93f-9fcc6cbb066e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/19990 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d4639e2a548442b2b87172998dd3c22f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/4998 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f4f6c7a1b90a42538e47ed3ece42b12e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Model Architecture\n",
        "\n",
        "We fine-tune DistilBERT, a Transformer-based neural network.\n",
        "\n",
        "Architecture:\n",
        "\n",
        "- Pretrained DistilBERT encoder\n",
        "- Linear classification head\n",
        "- Softmax output layer\n",
        "\n",
        "Training objective: minimize cross-entropy loss.\n"
      ],
      "metadata": {
        "id": "m63p190Osw5h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=len(labels),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id\n",
        ")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, y_true = eval_pred\n",
        "    y_pred = np.argmax(logits, axis=-1)\n",
        "    return {\n",
        "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
        "        \"f1_macro\": f1_score(y_true, y_pred, average=\"macro\")\n",
        "    }\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370,
          "referenced_widgets": [
            "cbecddcbd15e46448320f369c9129e87",
            "9f57c51b96394596824dc55d9c91cab6",
            "45428bb074234ada82f86d9ffc7e8622",
            "21918e34035a484d8bc7fc14f2a68866",
            "606d4fd9ed84427b8258979ff4480ba6",
            "0b66c1cad424495f82c522e1e72e8e35",
            "25a94bd08d6f4f4096a611a40381b3f1",
            "ab61546c305e43cebe8252e9f05bbd4c",
            "1ad0a2ccb5914a50b0fd7ebb7a7608a1",
            "d483003bca0c4bebb216912f34174260",
            "fe9d8ea9be534234aa1b47fb5187bb57"
          ]
        },
        "id": "US9Gy27tdsF_",
        "outputId": "aefd12a4-a895-47d0-c8f9-af23d4626987"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
            "WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/100 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cbecddcbd15e46448320f369c9129e87"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DistilBertForSequenceClassification LOAD REPORT from: distilbert-base-uncased\n",
            "Key                     | Status     | \n",
            "------------------------+------------+-\n",
            "vocab_layer_norm.bias   | UNEXPECTED | \n",
            "vocab_transform.weight  | UNEXPECTED | \n",
            "vocab_projector.bias    | UNEXPECTED | \n",
            "vocab_layer_norm.weight | UNEXPECTED | \n",
            "vocab_transform.bias    | UNEXPECTED | \n",
            "pre_classifier.bias     | MISSING    | \n",
            "pre_classifier.weight   | MISSING    | \n",
            "classifier.bias         | MISSING    | \n",
            "classifier.weight       | MISSING    | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
            "- MISSING\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers, inspect\n",
        "from transformers import TrainingArguments\n",
        "\n",
        "print(\"transformers version:\", transformers.__version__)\n",
        "print(\"transformers file:\", transformers.__file__)\n",
        "print(\"TrainingArguments init params contains evaluation_strategy?\",\n",
        "      \"evaluation_strategy\" in str(inspect.signature(TrainingArguments.__init__)))\n",
        "print(\"TrainingArguments init params contains eval_strategy?\",\n",
        "      \"eval_strategy\" in str(inspect.signature(TrainingArguments.__init__)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJlYH566eoPE",
        "outputId": "eb47ee96-60af-4b56-a888-ebedafc080a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "transformers version: 5.0.0\n",
            "transformers file: /usr/local/lib/python3.12/dist-packages/transformers/__init__.py\n",
            "TrainingArguments init params contains evaluation_strategy? False\n",
            "TrainingArguments init params contains eval_strategy? True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Training Configuration\n",
        "\n",
        "Hyperparameters:\n",
        "\n",
        "- Learning rate: 2e-5\n",
        "- Batch size: 16\n",
        "- Epochs: 2\n",
        "- Optimizer: AdamW\n",
        "- Metric: F1 Macro\n",
        "\n",
        "GPU acceleration is used for efficient fine-tuning.\n"
      ],
      "metadata": {
        "id": "Q8edcykJs1ug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args = TrainingArguments(\n",
        "    output_dir=\"sentiment_bert\",\n",
        "    eval_strategy=\"epoch\",     # <-- FIXED\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=2,\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1_macro\",\n",
        "    report_to=\"none\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "JgZPToCUdzb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorWithPadding, Trainer\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset=test_ds,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ],
      "metadata": {
        "id": "qrhJqMyOfi63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Model Training & Evaluation\n",
        "\n",
        "The pretrained transformer is fine-tuned\n",
        "on the labeled movie review dataset.\n",
        "\n",
        "Final performance metrics:\n",
        "\n",
        "- Accuracy ≈ 91%\n",
        "- F1 Macro ≈ 91%\n",
        "\n",
        "The model demonstrates strong generalization performance.\n"
      ],
      "metadata": {
        "id": "P6TSn0t4s61t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()\n",
        "trainer.evaluate()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383,
          "referenced_widgets": [
            "dd1510a8c6694ec2995412639ea874e7",
            "4fcbee4c2abd4f1ca9693b9620bf99e3",
            "eef3450c988c41ee8ed9ca54a3524749",
            "fa5557f7b34049e989ab435975bcdcca",
            "8bc21a90836b4f53ba54be06a89f71f3",
            "b6bec71bea754ca5b44eb2f05a84c725",
            "026b8c852c234b44962a9d5b6781c0d7",
            "6cc140238a034df5a7e1826b854a1d98",
            "fc00272029b2428d80967935db1e96f3",
            "ab046f2f42b54fa787189c53d7f8b2f2",
            "969edcc708e5448cbbb01050fa702c69",
            "db0b98879fa242f5bf62f6188299ac3b",
            "ec2579abe1c64a1889b08bebedd68740",
            "1378cb1f5dbd4a7b998acc62ab1396a0",
            "647b6bfb535e4fb7a732bbf164515b84",
            "a33eb48069e449368e8796768594822f",
            "0bb900550a694a16bc742b84c8b6c172",
            "9fa1fec72c1b43cbbc5220b6700e08a2",
            "a50c62878bc847efbd172f0f4f67de24",
            "bbb6322ce81a4b9b8fcecc8d8d8f0788",
            "3a67ad9bd5234e36b99ffddbc429b60b",
            "3c75a847d61a4f75a94c371b934d28a5"
          ]
        },
        "id": "gnJ9pQ1fglMV",
        "outputId": "9a8feb2e-c461-4b6c-cd42-d500f4d2796e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2500' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2500/2500 18:34, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.286090</td>\n",
              "      <td>0.259557</td>\n",
              "      <td>0.906763</td>\n",
              "      <td>0.906739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.174237</td>\n",
              "      <td>0.264505</td>\n",
              "      <td>0.913766</td>\n",
              "      <td>0.913764</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dd1510a8c6694ec2995412639ea874e7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "db0b98879fa242f5bf62f6188299ac3b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "There were missing keys in the checkpoint model loaded: ['distilbert.embeddings.LayerNorm.weight', 'distilbert.embeddings.LayerNorm.bias'].\n",
            "There were unexpected keys in the checkpoint model loaded: ['distilbert.embeddings.LayerNorm.beta', 'distilbert.embeddings.LayerNorm.gamma'].\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='313' max='313' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [313/313 00:40]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.2645047903060913,\n",
              " 'eval_accuracy': 0.913765506202481,\n",
              " 'eval_f1_macro': 0.9137639837814617,\n",
              " 'eval_runtime': 41.0904,\n",
              " 'eval_samples_per_second': 121.634,\n",
              " 'eval_steps_per_second': 7.617,\n",
              " 'epoch': 2.0}"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " # 9. Example of Prediction"
      ],
      "metadata": {
        "id": "GjyitfBUtdin"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def predict_with_proba(texts):\n",
        "    if isinstance(texts, str):\n",
        "        texts = [texts]\n",
        "\n",
        "    inputs = tokenizer(texts, return_tensors=\"pt\", truncation=True, padding=True, max_length=256)\n",
        "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = model(**inputs).logits\n",
        "        probs = F.softmax(logits, dim=-1).cpu().numpy()\n",
        "\n",
        "    preds = probs.argmax(axis=1)\n",
        "\n",
        "    for i, text in enumerate(texts):\n",
        "        pred_label = id2label[int(preds[i])]\n",
        "        prob_dict = {id2label[j]: float(probs[i][j]) for j in range(len(labels))}\n",
        "        print(\"\\nTEXT:\", text)\n",
        "        print(\"PRED:\", pred_label)\n",
        "        print(\"PROBS:\", prob_dict)\n",
        "\n",
        "predict_with_proba([\n",
        "    \"This movie is not as good.\",\n",
        "    \"Absolutely fantastic — I loved it.\"\n",
        "])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWGeNJKLfADD",
        "outputId": "5ad92136-3310-42a5-8046-d27830e4b1ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TEXT: This movie is not as good.\n",
            "PRED: negative\n",
            "PROBS: {'negative': 0.9902251362800598, 'positive': 0.009774923324584961}\n",
            "\n",
            "TEXT: Absolutely fantastic — I loved it.\n",
            "PRED: positive\n",
            "PROBS: {'negative': 0.008070720359683037, 'positive': 0.991929292678833}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. Interactive Prediction Demo\n",
        "\n",
        "Users can input custom movie reviews\n",
        "to observe real-time sentiment predictions\n",
        "and confidence scores.\n"
      ],
      "metadata": {
        "id": "yRlV8KF_tZ2Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def predict_texts(texts):\n",
        "    if isinstance(texts, str):\n",
        "        texts = [texts]\n",
        "\n",
        "    inputs = tokenizer(\n",
        "        texts,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        max_length=256\n",
        "    )\n",
        "\n",
        "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = model(**inputs).logits\n",
        "        probs = F.softmax(logits, dim=-1).cpu().numpy()\n",
        "\n",
        "    for text, p in zip(texts, probs):\n",
        "        pred_id = int(p.argmax())\n",
        "        pred_label = id2label[pred_id]\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"TEXT:\", text)\n",
        "        print(\"PREDICTION:\", pred_label)\n",
        "        print(\"CONFIDENCE:\", round(float(p[pred_id]), 4))\n",
        "        print(\"ALL PROBS:\")\n",
        "        for i in range(len(p)):\n",
        "            print(f\"  {id2label[i]}: {round(float(p[i]), 4)}\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Feel free edit this line ↓↓↓\n",
        "# -----------------------------\n",
        "\n",
        "user_input = input(\"Enter a movie review sentence: \")\n",
        "\n",
        "predict_texts(user_input)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVFAYSNkp5HX",
        "outputId": "cf9e069a-9163-4347-a40e-f653205415a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a movie review sentence: This is a relatively decent one.\n",
            "\n",
            "============================================================\n",
            "TEXT: This is a relatively decent one.\n",
            "PREDICTION: positive\n",
            "CONFIDENCE: 0.7926\n",
            "ALL PROBS:\n",
            "  negative: 0.2074\n",
            "  positive: 0.7926\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. Error Analysis\n",
        "\n",
        "We examine misclassified examples to understand\n",
        "model limitations.\n",
        "\n",
        "Observed challenges:\n",
        "\n",
        "- Comparative sentiment\n",
        "- Sarcasm\n",
        "- Pragmatic reversal\n",
        "- Contrastive structures\n"
      ],
      "metadata": {
        "id": "4_NHqPDZuio2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predict_texts([\n",
        "    \"I love it.\",\n",
        "    \"I love it. Not.\",\n",
        "    \"Great movie... said no one ever.\",\n",
        "    \"This was amazing... until it wasn't.\",\n",
        "    \"This movie is not as good as Titanic; it's already good enough.\",\n",
        "    \"I thought it was good; it was actually terrible.\"\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2G6_e8quFB7",
        "outputId": "588ca381-78c1-4135-fc44-f510b66b9b4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "TEXT: I love it.\n",
            "PREDICTION: positive\n",
            "CONFIDENCE: 0.9877\n",
            "ALL PROBS:\n",
            "  negative: 0.0123\n",
            "  positive: 0.9877\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "TEXT: I love it. Not.\n",
            "PREDICTION: positive\n",
            "CONFIDENCE: 0.823\n",
            "ALL PROBS:\n",
            "  negative: 0.177\n",
            "  positive: 0.823\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "TEXT: Great movie... said no one ever.\n",
            "PREDICTION: positive\n",
            "CONFIDENCE: 0.9909\n",
            "ALL PROBS:\n",
            "  negative: 0.0091\n",
            "  positive: 0.9909\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "TEXT: This was amazing... until it wasn't.\n",
            "PREDICTION: positive\n",
            "CONFIDENCE: 0.8426\n",
            "ALL PROBS:\n",
            "  negative: 0.1574\n",
            "  positive: 0.8426\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "TEXT: This movie is not as good as Titanic; it's already good enough.\n",
            "PREDICTION: negative\n",
            "CONFIDENCE: 0.9868\n",
            "ALL PROBS:\n",
            "  negative: 0.9868\n",
            "  positive: 0.0132\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "TEXT: I thought it was good; it was actually terrible.\n",
            "PREDICTION: negative\n",
            "CONFIDENCE: 0.9113\n",
            "ALL PROBS:\n",
            "  negative: 0.9113\n",
            "  positive: 0.0887\n",
            "============================================================\n"
          ]
        }
      ]
    }
  ]
}